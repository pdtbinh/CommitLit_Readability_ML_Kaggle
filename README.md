# CommitLit Readability Prize ML on Kaggle

This project includes the data, codes, and submissions for the CommonLit Readability Prize ML compettion on Kaggle. 

Model solution: Variants of RoBERTa (Robust Optimized BERT Pretraining Approach): XMLRoBERTa, RoBERTa-Base, RoBERTa-Large and combinations of those.

