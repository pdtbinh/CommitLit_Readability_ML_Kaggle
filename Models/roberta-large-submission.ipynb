{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "according-closer",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-06-22T14:06:16.208866Z",
     "iopub.status.busy": "2021-06-22T14:06:16.208282Z",
     "iopub.status.idle": "2021-06-22T14:06:21.969009Z",
     "shell.execute_reply": "2021-06-22T14:06:21.968353Z",
     "shell.execute_reply.started": "2021-06-13T10:24:48.799995Z"
    },
    "papermill": {
     "duration": 5.780593,
     "end_time": "2021-06-22T14:06:21.969170",
     "exception": false,
     "start_time": "2021-06-22T14:06:16.188577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras import backend as K\n",
    "from transformers import RobertaTokenizerFast, TFRobertaModel\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply, Embedding, Reshape, Flatten, Dropout, GRU, Dense\n",
    "from keras.layers import RepeatVector, Dense, Activation, Lambda, Softmax, Conv1D, LayerNormalization, Softmax, Multiply\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.utils import to_categorical\n",
    "from keras.initializers import Constant\n",
    "from keras.models import load_model, Model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau,ModelCheckpoint, EarlyStopping ,LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "commercial-thickness",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T14:06:21.986405Z",
     "iopub.status.busy": "2021-06-22T14:06:21.985851Z",
     "iopub.status.idle": "2021-06-22T14:06:44.465189Z",
     "shell.execute_reply": "2021-06-22T14:06:44.465831Z",
     "shell.execute_reply.started": "2021-06-13T10:24:54.626725Z"
    },
    "papermill": {
     "duration": 22.49012,
     "end_time": "2021-06-22T14:06:44.466176",
     "exception": false,
     "start_time": "2021-06-22T14:06:21.976056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaModel.\n",
      "\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at ../input/initial-roberta-large/roberta-large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained('../input/initial-tokenizer-large/tokenizer-large')\n",
    "roberta = TFRobertaModel.from_pretrained('../input/initial-roberta-large/roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "material-masters",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T14:06:44.490055Z",
     "iopub.status.busy": "2021-06-22T14:06:44.488474Z",
     "iopub.status.idle": "2021-06-22T14:06:44.490831Z",
     "shell.execute_reply": "2021-06-22T14:06:44.491221Z",
     "shell.execute_reply.started": "2021-06-13T10:25:19.863976Z"
    },
    "papermill": {
     "duration": 0.017154,
     "end_time": "2021-06-22T14:06:44.491345",
     "exception": false,
     "start_time": "2021-06-22T14:06:44.474191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tokenize a bunch of texts\n",
    "def tokenize_texts(texts, tokenizer, max_len):\n",
    "    tok = tokenizer.batch_encode_plus(texts.tolist(), \n",
    "                                          padding='max_length', \n",
    "                                          max_length=max_len, \n",
    "                                          truncation=True, \n",
    "                                          return_tensors='np')\n",
    "    return tok['input_ids'], tok['attention_mask']\n",
    "\n",
    "# Prepare sets\n",
    "def prepare_sets(is_train_csv, tokenizer, max_len):\n",
    "    # Retrieve dataframes\n",
    "    df        = pd.read_csv('../input/commonlitreadabilityprize/' + is_train_csv)\n",
    "    \n",
    "    # Retrieve inputs: IDs and mask\n",
    "    excerpts  = df['excerpt']\n",
    "    tokenized = tokenize_texts(excerpts, tokenizer, max_len)\n",
    "    ids       = tokenized[0]\n",
    "    mask      = tokenized[1]\n",
    "    \n",
    "    # Retrieve labels\n",
    "    targets = None\n",
    "    if is_train_csv == 'train.csv':\n",
    "        targets   = np.array(df['target'])\n",
    "    \n",
    "    return ids, mask, targets, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "advised-request",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T14:06:44.513451Z",
     "iopub.status.busy": "2021-06-22T14:06:44.511863Z",
     "iopub.status.idle": "2021-06-22T14:06:44.514397Z",
     "shell.execute_reply": "2021-06-22T14:06:44.514819Z",
     "shell.execute_reply.started": "2021-06-13T10:25:19.873397Z"
    },
    "papermill": {
     "duration": 0.016,
     "end_time": "2021-06-22T14:06:44.514941",
     "exception": false,
     "start_time": "2021-06-22T14:06:44.498941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to transform arrays to tensors\n",
    "def transform_to_tensors(x_train, x_val, y_train, y_val):\n",
    "    \n",
    "    train_dataset = (\n",
    "        tf.data.Dataset\n",
    "        .from_tensor_slices(({'input_1': x_train[0], 'input_2': x_train[1]}, y_train))\n",
    "        .shuffle(2048)\n",
    "        .batch(8)\n",
    "        .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    )\n",
    "    \n",
    "    valid_dataset = (\n",
    "        tf.data.Dataset\n",
    "        .from_tensor_slices(({'input_1': x_val[0], 'input_2': x_val[1]}, y_val))\n",
    "        .batch(8)\n",
    "        .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    )\n",
    "    \n",
    "    return train_dataset, valid_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "conservative-highlight",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T14:06:44.538066Z",
     "iopub.status.busy": "2021-06-22T14:06:44.536738Z",
     "iopub.status.idle": "2021-06-22T14:06:44.539145Z",
     "shell.execute_reply": "2021-06-22T14:06:44.539520Z",
     "shell.execute_reply.started": "2021-06-13T10:25:19.889044Z"
    },
    "papermill": {
     "duration": 0.017186,
     "end_time": "2021-06-22T14:06:44.539643",
     "exception": false,
     "start_time": "2021-06-22T14:06:44.522457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model(max_len, learning_rate, dc):\n",
    "    \n",
    "    # Inputs: IDs and mask\n",
    "    ids = Input(shape=(max_len,), dtype='int64')\n",
    "    mask = Input(shape=(max_len,), dtype='int64')\n",
    "    \n",
    "    # Processing\n",
    "    x = roberta(input_ids=ids, attention_mask=mask)['last_hidden_state']\n",
    "    x = x[:, 0, :]\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    # Output\n",
    "    pred = Dense(1, activation='linear', kernel_regularizer=regularizers.l1_l2(l1=1e-4, l2=1e-3),)(x)\n",
    "    \n",
    "    # Model\n",
    "    model = Model(inputs=[ids, mask], outputs=pred)\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, decay=dc),\n",
    "                  loss = [tf.keras.losses.MeanSquaredError()],\n",
    "                  metrics = [tf.keras.metrics.RootMeanSquaredError()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "received-ownership",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T14:06:44.563675Z",
     "iopub.status.busy": "2021-06-22T14:06:44.562824Z",
     "iopub.status.idle": "2021-06-22T14:07:08.471844Z",
     "shell.execute_reply": "2021-06-22T14:07:08.472323Z",
     "shell.execute_reply.started": "2021-06-13T10:26:21.278499Z"
    },
    "papermill": {
     "duration": 23.925242,
     "end_time": "2021-06-22T14:07:08.472483",
     "exception": false,
     "start_time": "2021-06-22T14:06:44.547241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "r_model = create_model(256, 1e-5, 2e-6)\n",
    "r_model.load_weights('../input/roberta-large-ckpt/ckpt_roberta_large.h5')\n",
    "\n",
    "test_set = prepare_sets('test.csv', tokenizer, 256)\n",
    "test_pred = r_model.predict([test_set[0], test_set[1]], test_set[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "departmental-ukraine",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T14:07:08.497072Z",
     "iopub.status.busy": "2021-06-22T14:07:08.493259Z",
     "iopub.status.idle": "2021-06-22T14:07:08.860029Z",
     "shell.execute_reply": "2021-06-22T14:07:08.859503Z",
     "shell.execute_reply.started": "2021-06-13T10:26:42.255544Z"
    },
    "papermill": {
     "duration": 0.38007,
     "end_time": "2021-06-22T14:07:08.860161",
     "exception": false,
     "start_time": "2021-06-22T14:07:08.480091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\n",
    "pred_df = {'id': test_df['id'], 'target': test_pred.reshape(-1)}\n",
    "pd.DataFrame(pred_df).to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-pillow",
   "metadata": {
    "papermill": {
     "duration": 0.006987,
     "end_time": "2021-06-22T14:07:08.874513",
     "exception": false,
     "start_time": "2021-06-22T14:07:08.867526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 61.713887,
   "end_time": "2021-06-22T14:07:11.287507",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-22T14:06:09.573620",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
